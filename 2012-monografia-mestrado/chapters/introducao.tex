\chapter{Introdução}
\label{introducao}

Experimentos científicos produzem terabytes de informações que precisam ser processadas e analisadas. A interação multidisciplinar entre a computação e outras áreas da ciência carece de ferramentas que ofereçam processamento massivo dos dados de seus experimentos científicos. Para que estes sejam processados, podem ser usados fluxos de trabalho científico que dividem uma consulta maior em partes menores, permitindo uma distribuição estratégica do processamento desses fluxos, visando minimizar o tempo de execução e o melhor aproveitamento dos recursos computacionais \cite{Simmhan2005}.

%Desta forma, os cientistas não precisam se aprofundar em conhecimentos computacionais avançados, necessários para processar e extrair informações de suas pesquisas. 

%A utilização de fluxos de trabalho científico é uma forma de encapsular a automatização de processos, compostos por dados que são transformados e transmitidos entre participantes, com uma certa regra procedimental, a fim de obter o resultado de um experimento científico \cite{Hollingsworth1995}.

Os experimentos científicos, normalmente utilizam um ambiente distribuído que ofereça recursos computacionais de alto desempenho. Neste ambiente, utilizam-se técnicas de computação distribuída que possibilitem tal processamento. Um ambiente distribuído envolve a coordenação e o compartilhamento dos recursos computacionais, armazenamento de dados e recursos de rede. 

%Como exemplo de ambientes distribuídos temos as \emph{grades} e as \emph{nuvens}. Uma \emph{grade}, é uma rede composta por nós distribuídos dinamicamente e geograficamente dispersos. Uma \emph{nuvem} é composta por aplicações entregues como serviços na Internet. Esses serviços são fornecidos por centrais de dados que oferecem recursos de \emph{software} e \emph{hardware} para a execução desses serviços \cite{Sharma2010,DeOliveira2010}.

%Alguns dos sistemas existentes exploram técnicas de paralelização tais como varredura de parâmetros e fragmentação de dados. Nesses sistemas, muitos recursos são utilizados para efetuar tal processamento, necessitando de um ambiente específico e controlado, como por exemplo uma máquina multi-processador ou um sistemas de \emph{cluster} \cite{DeOliveira2010}.

%grades e nuvens

Uma das dificuldades ao se trabalhar com fluxos de trabalhos científicos está no escalonamento das tarefas que os compõem. Além disso, é necessário planejar a alocação das tarefas de múltiplos fluxos de trabalho científico, a fim de otimizar a utilização dos recursos computacionais disponíveis. Por isto, é necessário um mecanismo para o escalonamento de tarefas. A técnica de resolução de problemas de planejamento em \UFPRsigla{IA} pode ser explorada para a elaboração de um plano de execução mais refinado \cite{Weld1999}.

%A computação nas nuvens vem se tornando popular, para ambientes com necessidade de alto poder de processamento. Isso se torna possível através da alocação de computadores pela Internet, que trabalham de forma coordenada para cumprir o mesmo objetivo. Alguns cientistas estão migrando seus experimentos que utilizam fluxos de trabalhos científicos para ambientes em nuvem, justamente por possibilitar a utilização de um ambiente customizável. Entretanto ainda é difícil para o cientista mapear um fluxo de trabalho em uma nuvem \cite{DeOliveira2010}.

%Muitos dos sistemas que utilizam um o processamento de fluxos de trabalhos científicos focam-se apenas em ambientes homogêneos. Um sistema homogêneo é formado por recursos com a mesma capacidade de processamento, enquanto que em ambientes heterogêneos os recursos podem possuir diferentes capacidades de processamento. Ao se mapear esse ambiente para uma nuvem, alguns aspectos devem ser observados, como por exemplo os custos para inicialização das máquinas ou para a transferência de dados de entrada e dados de saída.

Um problema de planejamento pode ser definido como o problema de encontrar uma sequência de ações que quando executada em um contexto que satisfaça um estado inicial do problema, vai atingir o objetivo do mesmo \cite{Weld1999}. Ao mapear computacionalmente situações do mundo real, nota-se a complexidade obtida por uma grande quantidade de escolhas na construção de um plano de ações, o que torna o problema intratável com algoritmos de busca convencionais.

O problema de escalonamento pode ser visto como um subproblema do problema de planejamento, no qual já se sabe quais são as ações que compõem o plano, o objetivo é encontrar uma ordenação coordenada destas ações. Ao tratar problemas complexos recomenda-se a utilização de metadados específicos do domínio, que auxiliam na busca de uma solução para o problema de planejamento. Um metadado é um dado que possui informação sobre outros dados. Uma dentre várias abordagens que utiliza metadados é chamada de proveniência de dados, que prevê as ações e comportamentos baseando-se nos históricos fornecidos em execuções anteriores \cite{Simmhan2005}.

Com a aplicação de técnicas de proveniência é possível obter um escalonamento refinado. Analisando o ambiente de execução e armazenando seu histórico, é possível extrair informações que auxiliam no processo de escalonamento. Por exemplo, se uma tarefa $s$ com determinadas características é executada com um tempo $t$ em determinado conjunto de nós, uma tarefa que possui as mesmas características $s'$ pode ser executada em um tempo próximo a $t$ no mesmo conjunto de nós. Assim é possível prever o tempo de execução, o que pode ajudar no processo de escalonamento. Depois que as tarefas estão escalonadas em seus respectivos nós, torna-se necessária uma estrutura que possibilite interpretar o plano e disparar a execução das tarefas em um ambiente distribuído. O gerenciador de execução faz com que os nós do sistema distribuído sejam capazes de executar as tarefas que lhe são designadas, respeitando o plano de execução anteriormente traçado.

% proposta
%Com o objetivo de refinar o processo de escalonamento, propõe-se a utilização de informações armazenadas em um banco de metadados que servirão como entrada para o planejador, que é o responsável pele escalonamento de tarefas e a construção de um plano de execução, contendo os passos a serem executados para a obtenção do resultado.

O objetivo deste trabalho é criar um sistema de distribuição de tarefas automático, capaz de aproveitar metadados dos históricos de execução para obter planos mais refinados. Para isso, propõe-se a utilização de técnicas para resolução de problemas de planejamento da área da \UFPRsigla{IA} com o objetivo de escalonar as tarefas dos fluxos de trabalho científico \cite{Deelman2009}. O trabalho proposto utiliza um modelo que atua como ligação entre o planejador e o gerenciador de execução. O planejador recebe como entrada os dados a serem processados, os operadores que atuarão sobre esses dados e as informações sobre os recursos que estão sendo utilizados na camada de execução. Como saída, gera-se um plano de execução. O gerenciador de execução, por sua vez, utiliza o plano de execução como entrada, além dos dados a serem processados, e os operadores que atuarão sobre esses dados. Como saída, são gerados os dados processados e informações com o estado atual dos recursos utilizados. 

%Apresenta-se um gerenciador de execução baseado no sistema \emph{PeerUnit} \cite{Almeida2008}, que originalmente foi concebido para executar testes em ambientes \UFPRsigla{P2P}. 

No modelo proposto são explorados dois tipos de paralelismo: \emph{paralelismo sobre os dados} e \emph{paralelismo sobre a execução}. O paralelismo sobre os dados é dividido em dois submodelos: \emph{direto} e \emph{paralelo por plano}. O modelo \emph{direto} escalona o processamento dos dados a partir de parâmetros inseridos na descrição do fluxo de trabalho. O modelo \emph{paralelo por plano} utiliza o planejador para dividir os dados entre os nós disponíveis. O \emph{paralelismo sobre a execução} é a execução paralela dos fluxos de trabalho. Seu escalonamento é feito pelo planejador, que a partir das informações provenientes dos recursos disponíveis, pondera quais fluxos podem ser executados em paralelo e quais os melhores nós para tal execução.

Cada fluxo de trabalho é dividido em tarefas. Na composição destes fluxos, são definidos dados de entrada e saída. Estes dados mapeiam relações de dependência, que serão analisadas posteriormente pelo planejador. Estas tarefas podem ser implementadas de diferentes maneiras, explorando ou não os tipos de paralelismo. Existe ainda um banco de metadados que armazena informações sobre execuções anteriores, bem como as características dos nós disponíveis para execução. O planejador utiliza estas informações para criar um plano de execução que define qual tarefa será executada em qual nó. Com o plano de execução pronto, uma camada de execução é acionada e dispara as tarefas para seus respectivos nós. Após a execução de uma tarefa, cada nó envia informações sobre a utilização de seus recursos, que são armazenados e utilizados para refinar uma próxima execução.

Um fluxo de trabalho científico pode conter ciclos em sua estrutura. Os ciclos aumentam a complexidade em sistemas que incluam o tratamento dessa classe de problemas \cite{Yongsun2004}. Este modelo não trata fluxos de trabalho que necessitem de uma especificação cíclica. Entretanto, uma das funcionalidades desenvolvidas, permite ao usuário especificar múltiplas entrada e saídas de dados (seção \ref{ex3}). Este recurso permite um encapsulamento de operadores que necessitem de ciclos, unindo-os em um outro operador capaz de executar as operações dos anteriotes.

Como resultados apresenta-se uma análise dos planos gerados e do comportamento do sistema em um cenário de execução. Os experimentos descrevem três implementações que utilizam as principais características do modelo proposto.

Este documento está organizado em capítulos. O capítulo \ref{revisao-bibliografica} apresenta uma revisão bibliográfica dos assuntos relacionados com o modelo proposto. O capítulo \ref{trabalhos-relacionados} apresenta-se os principais trabalhos utilizados como referência. No capítulo \ref{modelo} é apresentado o modelo proposto. O capítulo \ref{experimentos} descreve os experimentos. Apresenta-se um capítulo com a conclusão e os trabalhos futuros em \ref{conclusao}. Ao final de cada capítulo, apresenta-se uma seção de discussões, que descreve a relação dos tópicos abordados com o modelo proposto. O apêndice \ref{jshop} apresenta a primeira modelagem do problema utilizando a ferramenta JSHOP. O apêndice \ref{recursos} apresenta exemplos de códigos que representam as configurações utilizadas para o gerenciamento do sistema. O apêndice \ref{plan-files} apresenta exemplos de códigos gerados em \UFPRsigla{PDDL}. O apêndice \ref{components-description} apresenta uma descrição dos componentes do sistema. No apêndice \ref{peer-unit-file} apresenta-se um arquivo de configuração do sistema PeerUnit. E finalmente no apêndice \ref{source-codes} apresenta-se exemplos de códigos fonte utilizados para a implementação do sistema.